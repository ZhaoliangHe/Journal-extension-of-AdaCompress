\section{Related Works}
\label{sec: related_works}

As cloud-based computer vision services have become the norm for today's applications ~\cite{huynh2017deepmon, agrawal2015cloudcv}, many studies have been devoted to improving the cloud-based model execution, including model compression and data compression.

\subsection{Model Compression}

Though the accurate term is still for the community to debate, we use ``model compression'' to represent the studies on {\em compressing} and {\em moving} the deep learning models close to users. Many studies tried to compress the deep learning models and deploy them \emph{locally} ~\cite{prun_quanti, pruning_han, quantize, quantize_3bit, quantization, structured_pruning}, i.e., running an alternative ``smaller version'' of a computer vision model at the user end, to avoid the image upload so that to improve the inference efficiency. Other studies proposed to run a part of a deep learning model locally ~\cite{ILP_Decoupling, jalad, Edge_LBP, Neurosurgeon}, by decoupling the deep learning model into different parts, e.g., based on the layers in the deep learning model, so that a part of the inference is done locally to save some execution time. However, these solutions usually need to \emph{re-train} the model, using the original dataset of the model, which is not practical for today's cloud computer vision services that are merely a black box to end-users, e.g., in the form of a RESTful API.

\subsection{Data Compression}

Data compression solutions study how to compress the original data (e.g., a video or image) to be inferred by the cloud deep learning model, so that less traffic is used to upload the data to improve inference speed. Conventional data compression solutions (e.g., JPEG \cite{jpeg}, WebP \cite{calore2010meet}, JPEG2000 \cite{rabbani2002jpeg2000} etc.) and some recent neural network based compression solutions ~\cite{toderici2017full,theis2017lossy,toderici2015variable, rippel2017real} are initially designed for the Human-Visual System. In recent years, researchers found that the human visually optimized data compression solutions are not usually applicable to deep learning vision models. Delac et al.~\cite{delac2005effects} observed that, in some cases, higher compression level does not always deteriorate the model inference accuracy, even improves it slightly. Dodge et al.~\cite{dodge2016understanding} further discovered that besides the JPEG compression, four types of quality distortions (blur, noise, contrast, and the JPEG2000 compression) can also affect the performance in deep learning inference. Liu et al.~\cite{DeepN-JPEG} proposed that the conventional JPEG image compression framework is designed for the Human-Visual System which is not suitable for the deep neural network, leading to cloud computer vision services' accuracy degradation at lower images' compression quality level. %% \\

Based on these insights, Robert et al. \cite{torfason2018towards} tried to train the deep neural network from the compressed representations of an auto-encoder. Chao et al. \cite{chao2011preserving} proposed using variable quantization which is supported by the JPEG standard extension syntax \cite{dis199110918} to compress the macroblocks in images. Furthermore, they \cite{chao2013design} designed a quantization table based on the observed impact of scale-space processing on the discrete cosine transform (DCT) basis functions for JPEG images, achieving similar inference performance with reduced image size. Liu et al. \cite{DeepN-JPEG} proposed DeepN-JPEG that redesigns the quantization table by linking statistical information of refined features and defining quantization values so that the compressed image size is reduced for deep learning models. Chamain et al. \cite{2019quannet} proposed a joint optimization of image classification network coupled with the image quantization, achieving image size reduction of JPGE2000 \cite{rabbani2002jpeg2000} encoded images. Recently, Lionel et al. \cite{gueguen2018faster} presented a new type of neural network that infers directly from the discrete cosine transform (DCT) coefficients in the middle of the JPEG codec. Baluja et al.~\cite{baluja2019task} proposed task-specific compression that compresses images based on the end-use of images. %% \\

However, such proposals all need one to understand the characteristics of the cloud-end deep learning model and have access to the original training dataset, to generate the appropriate color space and/or compression schemes. To the best of our knowledge, we are the first to propose an adaptive compression configuration solution named AdaCompress \cite{2019adacompress} that learns the deep learning model by itself. We design an agent that adaptively chooses the compression level according to the input image's features and backend deep learning models. 

In this extension paper, we improve previous mechanism to cut down the uploading file size overhead effectively, add DeepN-JPEG comparative experiment, and amend the manuscript significantly. Especially on the DeepN-JPEG comparative experiment, since Liu et al. \cite{DeepN-JPEG} evaluated the DeepN-JPEG framework on the ImageNet dataset by using four state-of-the-art DNN models (AlexNet \cite{AlexNet-krizhevsky2012imagenet}, VGG \cite{VGG-simonyan2014very}, GoogLeNet \cite{GoogleNet-szegedy2015going} and ResNet \cite{ResNet-he2016deep}) on local terminal devices, which are different from cloud computer vision services. For comparison purpose, we implement the DeepN-JPEG framework according to their paper and evaluate the size reduction and accuracy performance using the ImageNet dataset and the metrics in Sec.\ref{subsec:metrics} on three cloud deep learning services (Amazon Rekognition, Face++ and Baidu Vision), the same experiment configuration as the AdaCompress's.

%Liu et al. \cite{DeepN-JPEG} developed the DeepN-JPEG framework, a deep %neural network favorable JPEG-based image compression framework.